{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from numpy                 import array\n",
    "from sklearn               import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models          import Sequential\n",
    "from keras.layers          import *\n",
    "from sklearn               import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten,Conv2D, MaxPool2D,LSTM,Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers          import *\n",
    "from keras.models import save_model,load_model\n",
    "from numpy import save,load\n",
    "from sklearn.model_selection import KFold\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 INFO 和 WARNING 信息\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dscribe.descriptors import SOAP\n",
    "from dscribe.descriptors import MBTR,ACSF,CoulombMatrix,EwaldSumMatrix,SineMatrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core.surface import Slab\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "import ase.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62852069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####decribe parameters#####\n",
    "rcut = 6\n",
    "#####decribe parameters#####\n",
    "sm = SineMatrix(\n",
    "    n_atoms_max=96,\n",
    "    permutation=\"sorted_l2\",\n",
    "    sparse=False,\n",
    "    flatten=False)\n",
    "ew=EwaldSumMatrix(\n",
    "    n_atoms_max=96,\n",
    "    permutation=\"none\",flatten=False,sparse=False)\n",
    "acsf=ACSF(species=['Na','Mg','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Rb','Sr','Y','Zr','Nb','Mo','Tc','Rh','Pd','Ag','Cd','Cs','Ba','Os','Re','Ir','Pt','Au','Ga', 'In', 'Sn', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Hg', 'Tl', 'Pb', 'Bi', 'Li', 'Al','Ru','O'],\n",
    "# acsf=ACSF(species=['Na','Mg','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Rb','Sr','Y','Zr','Nb','Mo','Tc','Rh','Pd','Ag','Cd','Cs','Ba','Os','Re','Ir','Pt','Au','Ru','O'],\n",
    "    rcut=rcut,\n",
    "    periodic=True,\n",
    "    g2_params=[[1, 1], [1, 2], [1, 3]],\n",
    "    g4_params=[[1, 1, 1], [1, 2, 1], [1, 1, -1], [1, 2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "my_key='BJU2qDd4gpCPO0rf'\n",
    "from pymatgen.core import Structure, Lattice\n",
    "from pymatgen.core import Molecule\n",
    "from pymatgen.analysis.adsorption import *\n",
    "from pymatgen.core.surface import generate_all_slabs\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from matplotlib import pyplot as plt\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.vasp.inputs import Poscar\n",
    "from pymatgen.io.vasp.inputs import Kpoints\n",
    "from pymatgen.io.vasp.inputs import Incar\n",
    "from pymatgen.io.vasp.inputs import Potcar\n",
    "from pymatgen.io.vasp.inputs import PotcarSingle\n",
    "from numpy import array\n",
    "from pymatgen.io.vasp.sets import MPRelaxSet\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import re\n",
    "import numpy as np\n",
    "def sum_all(object_list):\n",
    "    sum_result=0\n",
    "    for strings in object_list:\n",
    "        b=int(strings)\n",
    "        sum_result+=b\n",
    "    return sum_result\n",
    "import random\n",
    "m= MPRester(my_key)\n",
    "element_list=['K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Rb','Sr','Y','Zr','Nb','Mo','Tc','Rh','Cs','Ba','Os','Re','Ir']\n",
    "extra_element_list=['Ga', 'In', 'Sn', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Hg', 'Tl', 'Pb', 'Bi', 'Li', 'Al']\n",
    "\n",
    "\n",
    "RuO2=m.get_structure_by_material_id('mp-825')\n",
    "struct = SpacegroupAnalyzer(RuO2).get_conventional_standard_structure()\n",
    "struct=reorient_z(struct)\n",
    "slabs = generate_all_slabs(struct, 1,12.0, 15.0, center_slab=True)\n",
    "m_index=(1,1,0)\n",
    "slab_dict = {slab.miller_index:slab for slab in slabs}                   \n",
    "RuO2_110=slab_dict[m_index]\n",
    "RuO2_110.make_supercell([[2,0,0],\n",
    "                          [0,2,0],\n",
    "                          [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec180f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_crystal_to_des(ase_atoms):\n",
    "    des1=sm.create(ase_atoms,n_jobs=-1)\n",
    "    des2=ew.create(ase_atoms,n_jobs=-1)\n",
    "    des3=acsf.create(ase_atoms,n_jobs=-1)\n",
    "    new_des=np.concatenate((des1,des2),axis=1)\n",
    "    new_des=np.concatenate((new_des,des3),axis=1)\n",
    "    new_des=new_des.reshape(768,969)\n",
    "    return new_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dscribe 1.2.1 numpy 1.23.5\n",
    "def load_trained_domain_adapted_model(model_type, saved_model_path):\n",
    "    # Load the model\n",
    "    if model_type in [7, 8]:  # For TCN models\n",
    "        #laptop running have to change to complie=False and tf....\n",
    "        current_model = tf.keras.models.load_model(saved_model_path, custom_objects={'TCN': TCN},compile=False)\n",
    "    else:\n",
    "        current_model = tf.keras.models.load_model(saved_model_path,compile=False)\n",
    "    return current_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c283d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_model(new_des, loaded_model, INPUT_SCALER, OUTPUT_SCALER, model_type):\n",
    "    # 对新晶体数据进行归一化\n",
    "    new_des_normalized = INPUT_SCALER.transform(new_des.reshape(-1, new_des.shape[-1])).reshape(new_des.shape)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    predicted = loaded_model.predict(new_des_normalized.reshape(1, *new_des_normalized.shape),verbose=0)\n",
    "\n",
    "    # 特殊处理模型类型6\n",
    "    if model_type == 6:\n",
    "        # 确保预测结果的形状正确\n",
    "        predicted = predicted.reshape(-1, 1)\n",
    "    # 逆归一化预测结果\n",
    "    predicted_original = OUTPUT_SCALER.inverse_transform(predicted)\n",
    "    return predicted_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312620d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model_3=load_trained_domain_adapted_model(3,\"Domain_Adapted_SLAB_3.h5\")\n",
    "loaded_model_5=load_trained_domain_adapted_model(5,\"Domain_Adapted_SLAB_5.h5\")\n",
    "loaded_model_6=load_trained_domain_adapted_model(6,\"Domain_Adapted_SLAB_6.h5\")\n",
    "loaded_model_7=load_trained_domain_adapted_model(7,\"Domain_Adapted_SLAB_7.h5\")\n",
    "loaded_model_9=load_trained_domain_adapted_model(9,\"Domain_Adapted_SLAB_9.h5\")\n",
    "SLAB_INPUT_SCALER_B=joblib.load(\"SLAB_INPUT_SCALER_B.pkl\")\n",
    "SLAB_OUTPUT_SCALER_B=joblib.load(\"SLAB_OUTPUT_SCALER_B.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19364caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(new_des):\n",
    "    predictions = [\n",
    "        predict_single_model(new_des, loaded_model_3, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 3)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_5, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 5)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_6, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 6)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_7, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 7)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_9, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 9)[0][0]\n",
    "    ]\n",
    "    variance = np.var(predictions)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_energy(new_des):\n",
    "    #0.9950695604822077\n",
    "    predict_3=predict_single_model(new_des,loaded_model_3,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,3)[0][0]\n",
    "    #0.9965353226220658\n",
    "    predict_5=predict_single_model(new_des,loaded_model_5,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,5)[0][0]\n",
    "    #0.996410743935558\n",
    "    predict_6=predict_single_model(new_des,loaded_model_6,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,6)[0][0]\n",
    "    #0.9938711994655637\n",
    "    predict_7=predict_single_model(new_des,loaded_model_7,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,7)[0][0]\n",
    "    #0.9973437346125353\n",
    "    predict_9=predict_single_model(new_des,loaded_model_9,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,9)[0][0]\n",
    "    sum_weight=0.9950695604822077+0.9965353226220658+0.996410743935558+0.9938711994655637+0.9973437346125353\n",
    "    sum_result=0.9950695604822077*predict_3+0.9965353226220658*predict_5+0.996410743935558*predict_6+0.9938711994655637*predict_7+0.9973437346125353*predict_9\n",
    "    return sum_result/sum_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ase_atoms = AseAtomsAdaptor.get_atoms(RuO2_110)\n",
    "base_des_ruo2=convert_crystal_to_des(ase_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruo2_slab_predict=calculate_weighted_energy(base_des_ruo2)\n",
    "print(ruo2_slab_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3286ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pymatgen.core.surface import Slab\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "def calculate_energy(new_structure):\n",
    "    ase_atoms = AseAtomsAdaptor.get_atoms(new_structure)\n",
    "    new_des=convert_crystal_to_des(ase_atoms)\n",
    "    weighted_energy_final=calculate_weighted_energy(new_des)\n",
    "#     print(weighted_energy_final)\n",
    "    return weighted_energy_final\n",
    "\n",
    "# 定义适应度函数\n",
    "def evaluate(individual):\n",
    "    # 根据个体（染色体）创建新的晶体结构\n",
    "    new_structure = RuO2_110.copy()\n",
    "    dopants = ['Ca', 'Ca', 'Ca', 'Mn', 'Mn', 'Pr']  # 根据配方\n",
    "    for i, site in enumerate(individual):\n",
    "        new_structure.replace(site, dopants[i])\n",
    "    # 计算并返回能量\n",
    "    energy = calculate_energy(new_structure)\n",
    "    return (energy,)  # 注意这里返回的是一个元组\n",
    "\n",
    "# 遗传算法参数\n",
    "NUM_SITES = 32  # 晶格中的Ru原子数量\n",
    "NUM_DOPANTS = 6  # 掺杂原子总数\n",
    "\n",
    "# 创建不重复的个体\n",
    "def create_individual():\n",
    "    return random.sample(range(NUM_SITES), NUM_DOPANTS)\n",
    "# 自定义交叉操作\n",
    "def cxTwoPointCopy(ind1, ind2):\n",
    "    tools.cxTwoPoint(ind1, ind2)\n",
    "    # 修正重复元素\n",
    "    fix_duplicate(ind1)\n",
    "    fix_duplicate(ind2)\n",
    "    return ind1, ind2\n",
    "\n",
    "# 自定义变异操作\n",
    "def mutShuffleIndexes(individual, indpb):\n",
    "    tools.mutShuffleIndexes(individual, indpb)\n",
    "    # 修正重复元素\n",
    "    fix_duplicate(individual)\n",
    "    return individual,\n",
    "\n",
    "# 修正重复元素的函数\n",
    "def fix_duplicate(individual):\n",
    "    unique_sites = set(individual)\n",
    "    for i in range(len(individual)):\n",
    "        while individual[i] in unique_sites:\n",
    "            individual[i] = random.randrange(NUM_SITES)\n",
    "        unique_sites.add(individual[i])\n",
    "\n",
    "# 创建适应度类和个体类\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # 最小化问题\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# 初始化工具箱\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"indices\", random.sample, range(NUM_SITES), NUM_DOPANTS)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "toolbox.register(\"mate\", cxTwoPointCopy)\n",
    "toolbox.register(\"mutate\", mutShuffleIndexes, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 运行遗传算法\n",
    "def run_genetic_algorithm():\n",
    "    pop = toolbox.population(n=500)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", lambda x: min(v[0] for v in x))  # 修改最小值统计\n",
    "    stats.register(\"avg\", lambda x: sum(v[0] for v in x) / len(x))  # 修改平均值统计\n",
    "\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, \n",
    "                                   stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    return hof[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_repeat_time in range(1,26):\n",
    "    start_time = time.time()\n",
    "    best_structure = run_genetic_algorithm()\n",
    "    end_time = time.time()\n",
    "    print(\"best_doping_structure\", best_structure,\"monte_carlo times:\",run_repeat_time)\n",
    "    print(f\"Completed in {end_time - start_time:.2f} seconds\")\n",
    "    run_repeat_time+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
