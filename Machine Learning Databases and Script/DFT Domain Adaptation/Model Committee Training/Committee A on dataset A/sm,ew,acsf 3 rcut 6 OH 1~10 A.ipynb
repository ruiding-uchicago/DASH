{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ase.io\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dscribe.descriptors import SOAP\n",
    "from dscribe.descriptors import MBTR,ACSF,CoulombMatrix,EwaldSumMatrix,SineMatrix \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from numpy                 import array\n",
    "from sklearn               import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models          import Sequential\n",
    "from keras.layers          import *\n",
    "from sklearn               import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten,Conv2D, MaxPool2D,LSTM,Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers          import *\n",
    "from keras.models import save_model,load_model\n",
    "from numpy import save,load\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MSE  ：均方误差    ----->  预测值减真实值求平方后求均值\n",
    "RMSE ：均方根误差  ----->  对均方误差开方\n",
    "MAE  ：平均绝对误差----->  预测值减真实值求绝对值后求均值\n",
    "R2   ：决定系数，可以简单理解为反映模型拟合优度的重要的统计量\n",
    "\"\"\"\n",
    "def compute_metrics(pred,real):\n",
    "    MSE   = metrics.mean_squared_error(pred, real)\n",
    "    RMSE  = metrics.mean_squared_error(pred, real)**0.5\n",
    "    MAE   = metrics.mean_absolute_error(pred, real)\n",
    "    R2    = metrics.r2_score(pred, real)\n",
    "    print('均方误差: %.5f' % MSE)\n",
    "    print('均方根误差: %.5f' % RMSE)\n",
    "    print('平均绝对误差: %.5f' % MAE)\n",
    "    print('R2: %.5f' % R2)\n",
    "    return [MSE,RMSE,MAE,R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ba683",
   "metadata": {},
   "outputs": [],
   "source": [
    "######specify the input and output######\n",
    "data_input=np.load('data_input_sm_ew_acsf_rcut6_A.npy')\n",
    "data_output=np.load('data_output_sm_ew_acsf_rcut6_OH_A.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建构模型\n",
    "def set_up_model(model_type,X_train,X_test,y_train,y_test):\n",
    "    if model_type == 1:\n",
    "        # 双向 LSTM\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(100),\n",
    "                                input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    if model_type == 2: \n",
    "        # simple RNN\n",
    "        model = Sequential()\n",
    "        model.add(SimpleRNN(units=100, return_sequences=True,activation='relu',\n",
    "                       input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(SimpleRNN(units=100))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    if model_type == 3:\n",
    "    #     GRU\n",
    "        model = Sequential()\n",
    "        model.add(GRU(units=100, return_sequences=True,activation='relu',\n",
    "                       input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(GRU(units=100))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    if model_type == 4:\n",
    "        #simple one layer CNN\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, activation='relu', \n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(units=y_train.shape[1]))\n",
    "    if model_type == 5:\n",
    "        #multilayer CNN\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', \n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(units=y_train.shape[1]))\n",
    "    if model_type == 6:\n",
    "        #CNN-LSTM\n",
    "#         y_train_sp = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "#         y_test_sp = y_test.reshape((y_test.shape[0], y_test.shape[1], 1))\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(RepeatVector(y_train.shape[1]))\n",
    "        model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "        model.add(TimeDistributed(Dense(y_train.shape[1])))\n",
    "\n",
    "    if model_type == 7:\n",
    "        #单层TCN\n",
    "        model = Sequential([\n",
    "        TCN(input_shape=(X_train.shape[1],X_train.shape[2]),\n",
    "            nb_filters=64,\n",
    "            kernel_size=2,\n",
    "            nb_stacks=1,\n",
    "            dilations=(1, 2, 4, 8, 16,32,64,128,256,512),\n",
    "            padding='causal',\n",
    "            use_skip_connections=True,\n",
    "            dropout_rate=0.0,\n",
    "            return_sequences=False,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            use_batch_norm=False,\n",
    "            use_layer_norm=False,\n",
    "            use_weight_norm=False,\n",
    "            ),\n",
    "        Dense(y_train.shape[1], activation='linear')\n",
    "    ])\n",
    "    if model_type == 8:\n",
    "        #多层TCN\n",
    "        model = Sequential([\n",
    "        TCN(input_shape=(X_train.shape[1],X_train.shape[2]),\n",
    "            nb_filters=64,\n",
    "            kernel_size=2,\n",
    "            nb_stacks=1,\n",
    "            dilations=(1, 2, 4, 8, 16,32,64,128,256,512),\n",
    "            padding='causal',\n",
    "            use_skip_connections=True,\n",
    "            dropout_rate=0.0,\n",
    "            return_sequences=True,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            use_batch_norm=False,\n",
    "            use_layer_norm=False,\n",
    "            use_weight_norm=False,\n",
    "            ),\n",
    "        TCN(\n",
    "            return_sequences=False\n",
    "            ),\n",
    "        Dense(y_train.shape[1], activation='linear')\n",
    "    ])\n",
    "    if model_type == 9:\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=128, kernel_size=2, activation='relu', \n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(units=y_train.shape[1]))\n",
    "    if model_type == 10:  \n",
    "        model = Sequential()\n",
    "        # 表示我们的网络将学习16个滤波器 每个滤波器的大小都是5×5，步长为1\n",
    "        model.add(Conv2D(32, kernel_size=2, strides=1, padding='valid', input_shape=(X_train.shape[1],X_train.shape[2],1),activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        model.add(Conv2D(16, kernel_size=2, strides=1, padding='valid',activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        # 展开\n",
    "        model.add(Flatten())\n",
    "        # 接下来相当于有两层full-connected网络\n",
    "        # 120个神经元 全连接网络\n",
    "        model.add(Dense(100,activation=\"relu\"))\n",
    "        # model.add(Dense(50,activation=\"relu\"))\n",
    "        # 84个神经元 全连接网络\n",
    "        model.add(Dense(y_train.shape[1],activation=\"linear\"))\n",
    "    if model_type==11:\n",
    "        model = Sequential()\n",
    "        # 表示我们的网络将学习6个滤波器 每个滤波器的大小都是3×3，步长为1\n",
    "        model.add(Conv2D(128, kernel_size=2, strides=1, padding='valid', input_shape=(X_train.shape[1],X_train.shape[2],1),activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        # 表示我们的网络将学习16个滤波器 每个滤波器的大小都是5×5，步长为1\n",
    "        model.add(Conv2D(64, kernel_size=2, strides=1, padding='valid',activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        model.add(Conv2D(32, kernel_size=2, strides=1, padding='valid',activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        # 展开\n",
    "        model.add(Flatten())\n",
    "        # 接下来相当于有两层full-connected网络\n",
    "        # 120个神经元 全连接网络\n",
    "        model.add(Dense(100,activation=\"relu\"))\n",
    "        # model.add(Dense(50,activation=\"relu\"))\n",
    "        # 84个神经元 全连接网络\n",
    "        model.add(Dense(y_train.shape[1],activation=\"linear\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ead91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type,model,number_batchsize,n_epochs,X_train,X_test,y_train,y_test):\n",
    "    print('type of model is',model_type)\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        batch_size=number_batchsize, \n",
    "                        epochs=n_epochs, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        validation_freq=1)                  #测试的epoch间隔数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model_type,model,Input):\n",
    "    pred=model.predict(Input)\n",
    "    if model_type in [8,9]:\n",
    "        pred=pred.reshape(pred.shape[0],pred.shape[1])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eed6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MAE_within_percent(pred_test,real_test,pred_train,real_train,threshold):\n",
    "    difference_test=abs(pred_test-real_test)\n",
    "    difference_train=abs(pred_train-real_train)\n",
    "    i_test=0\n",
    "    i_train=0\n",
    "    for each in difference_test:\n",
    "        if each<threshold:\n",
    "            i_test+=1\n",
    "    for each in difference_train:\n",
    "        if each<threshold:\n",
    "            i_train+=1\n",
    "    percent_train=i_train/len(difference_train)\n",
    "    percent_test=i_test/len(difference_test)\n",
    "    return percent_train,percent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std_and_best_model_serie_number(cvscores_result):\n",
    "    MSE_LIST=[]\n",
    "    RMSE_LIST=[]\n",
    "    MAE_LIST=[]\n",
    "    R2_LIST=[]\n",
    "    PERCENT_LIST=[]\n",
    "    for each_list in cvscores_result:\n",
    "        MSE_LIST.append(each_list[0])\n",
    "        RMSE_LIST.append(each_list[1])\n",
    "        MAE_LIST.append(each_list[2])\n",
    "        R2_LIST.append(each_list[3])\n",
    "        PERCENT_LIST.append(each_list[4])\n",
    "    print('metrics  mean  std')\n",
    "    print('MSE',np.mean(MSE_LIST), np.std(MSE_LIST))\n",
    "    print('RMSE',np.mean(RMSE_LIST), np.std(RMSE_LIST))\n",
    "    print('MAE',np.mean(MAE_LIST), np.std(MAE_LIST))\n",
    "    print('R2',np.mean(R2_LIST), np.std(R2_LIST))\n",
    "    print('PERCENT',np.mean(PERCENT_LIST), np.std(PERCENT_LIST))\n",
    "    return R2_LIST.index(max(R2_LIST)),np.mean(R2_LIST),np.mean(PERCENT_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_in_cv_and_save(predict_target,model_type,X_cv,y_cv,X_train,X_test,y_train,y_test,lr,loss_type,batch_number,epoch_number,Outputscaler):\n",
    "    print('now model type is',model_type)\n",
    "    cvscores_TRAIN=[]\n",
    "    cvscores_TEST=[]\n",
    "    trained_model_list=[]\n",
    "    kfold = KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "    for train, test in kfold.split(X_cv, y_cv):\n",
    "        #####build up model and train######\n",
    "        current_model=set_up_model(model_type,X_train,X_test,y_train,y_test)\n",
    "        current_model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss_type)  # 损失函数用均方误差\n",
    "        train_model(model_type,current_model,batch_number,epoch_number,X_cv[train],X_cv[test],y_cv[train],y_cv[test])\n",
    "        trained_model_list.append(current_model)\n",
    "        #####give predictions#####\n",
    "        try:\n",
    "            if model_type==6:\n",
    "                pred_test=prediction(model_type,current_model,X_cv[test])\n",
    "                pred_train=prediction(model_type,current_model,X_cv[train])\n",
    "                \n",
    "                pred_test=pred_test.reshape(-1,1)\n",
    "                pred_train=pred_train.reshape(-1,1)\n",
    "                \n",
    "                pred_train=Outputscaler.inverse_transform(pred_train)\n",
    "                pred_test=Outputscaler.inverse_transform(pred_test)\n",
    "                \n",
    "                print('here')\n",
    "                \n",
    "                real_train=Outputscaler.inverse_transform(y_cv[train].reshape(-1,1))\n",
    "                real_test=Outputscaler.inverse_transform(y_cv[test].reshape(-1,1))\n",
    "                \n",
    "            else:\n",
    "                pred_test=prediction(model_type,current_model,X_cv[test])\n",
    "                pred_train=prediction(model_type,current_model,X_cv[train])\n",
    "\n",
    "                pred_train=Outputscaler.inverse_transform(pred_train)\n",
    "                pred_test=Outputscaler.inverse_transform(pred_test)\n",
    "\n",
    "                real_train=Outputscaler.inverse_transform(y_cv[train])\n",
    "                real_test=Outputscaler.inverse_transform(y_cv[test])\n",
    "\n",
    "            TRAIN_SCORES=compute_metrics(pred_train,real_train)\n",
    "            TEST_SCORES=compute_metrics(pred_test,real_test)\n",
    "            \n",
    "            percent_train,percent_test=compute_MAE_within_percent(pred_test, real_test, pred_train, real_train, 0.05)\n",
    "            TRAIN_SCORES.append(percent_train)\n",
    "            TEST_SCORES.append(percent_test)\n",
    "            ###train and test scores###\n",
    "            cvscores_TRAIN.append(TRAIN_SCORES)\n",
    "            cvscores_TEST.append(TEST_SCORES)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    best_model_number,average_R2,average_percent=get_mean_and_std_and_best_model_serie_number(cvscores_TEST)\n",
    "    print('best in the cvs are the: ',best_model_number)\n",
    "    trained_model_list[best_model_number].save(predict_target+'_'+str(model_type)+'.h5')\n",
    "    return trained_model_list[best_model_number],average_R2,average_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ada9c4",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "Minmaxsc  = MinMaxScaler(feature_range=(0, 1))\n",
    "Minmaxsc2  = MinMaxScaler(feature_range=(0, 1))\n",
    "Stdsc  = StandardScaler()\n",
    "Stdsc2  = StandardScaler()\n",
    "MAsc  = MaxAbsScaler()\n",
    "MAsc2  = MaxAbsScaler()\n",
    "Rsc  = RobustScaler()\n",
    "Rsc2  = RobustScaler()\n",
    "\n",
    "X = Minmaxsc.fit_transform(data_input.reshape(-1, data_input.shape[-1])).reshape(data_input.shape)\n",
    "y = Stdsc2.fit_transform(data_output.reshape(-1,1))\n",
    "random_seed=1\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=random_seed,test_size=0.1)\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "\n",
    "train_score_list=[]\n",
    "test_score_list=[]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f82d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range (1,11):\n",
    "    if i ==10:\n",
    "        bn=64\n",
    "    else:\n",
    "        bn=128\n",
    "    serial_model,serial_R2,serial_percent=evaluate_in_cv_and_save('OH',i,X,y,X_train,X_test,y_train,y_test,0.001,'mse',bn,100,Stdsc2)\n",
    "    model_list.append(serial_model)\n",
    "    R2_list.append(serial_R2)\n",
    "    percent_list.append(serial_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100a554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
