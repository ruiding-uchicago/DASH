{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import catboost\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm \n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed=75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70761ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_roc_curve(y_train, y_pred_train, y_test, y_pred_test, title):\n",
    "    fig, ax = plt.subplots()  # This creates a new figure and axes\n",
    "\n",
    "    for data, label, dataset in [(y_train, y_pred_train, 'Train'), (y_test, y_pred_test, 'Test')]:\n",
    "        if len(data.shape) > 1:  # Check if it's a multi-class problem\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "            for i in range(data.shape[1]):\n",
    "                fpr[i], tpr[i], _ = roc_curve(data.iloc[:, i], label[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            \n",
    "            for i in range(data.shape[1]):\n",
    "                ax.plot(fpr[i], tpr[i], label=f'ROC curve of {dataset} class {i} (area = {roc_auc[i]:.2f})')\n",
    "        else:\n",
    "            # Assuming the second column of label array represents the positive class probabilities\n",
    "            fpr, tpr, _ = roc_curve(data, label[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            ax.plot(fpr, tpr, label=f'{dataset} ROC curve (area = {roc_auc:.2f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curve - {title}')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return fig, ax  # Return the Figure and Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_print_plot(data_input, X_train, X_test, y_train, y_test, algorithm_name, model):\n",
    "    # Predict labels for all data, train data, and test data\n",
    "    y_pred_all = model.predict(data_input)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Predict probabilities for all data, train data, and test data\n",
    "    y_pred_proba_all = model.predict_proba(data_input)\n",
    "    y_pred_proba_train = model.predict_proba(X_train)\n",
    "    y_pred_proba_test = model.predict_proba(X_test)\n",
    "    \n",
    "\n",
    "    # Plot ROC curve for both train and test data\n",
    "    fig,ax=plot_roc_curve(y_train, y_pred_proba_train, y_test, y_pred_proba_test, title=algorithm_name)\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00962e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########wrapping classification metrics for later calls##########\n",
    "def compute_classification_metrics(target, prediction):\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    f1 = f1_score(target, prediction)\n",
    "    auc = roc_auc_score(target, prediction)\n",
    "    return accuracy, f1, auc\n",
    "\n",
    "def gridsearch(model, param, algorithm_name, X_train, y_train, X_test, y_test):\n",
    "    grid = GridSearchCV(model, param_grid=param, scoring='f1', cv=10, n_jobs=-1, verbose=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    prediction_train = best_model.predict(X_train)\n",
    "    prediction_test = best_model.predict(X_test)\n",
    "    \n",
    "    # Combine train and test predictions and true values\n",
    "    combined_predictions = np.concatenate([prediction_train, prediction_test])\n",
    "    combined_true_values = np.concatenate([y_train, y_test])\n",
    "    \n",
    "    accuracy_train, f1_train, auc_train = compute_classification_metrics(y_train, prediction_train)\n",
    "    accuracy_test, f1_test, auc_test = compute_classification_metrics(y_test, prediction_test)\n",
    "    accuracy_all, f1_all, auc_all = compute_classification_metrics(combined_true_values, combined_predictions)\n",
    "\n",
    "    print(algorithm_name)\n",
    "    print('Best Classifier:', grid.best_params_)\n",
    "    print('--- Training Data ---')\n",
    "    print('Accuracy:', accuracy_train, 'F1:', f1_train, 'AUC:', auc_train)\n",
    "    print('--- Test Data ---')\n",
    "    print('Accuracy:', accuracy_test, 'F1:', f1_test, 'AUC:', auc_test)\n",
    "    print('--- All Data ---')\n",
    "    print('Accuracy:', accuracy_all, 'F1:', f1_all, 'AUC:', auc_all)\n",
    "    \n",
    "    return best_model, (accuracy_test+f1_test+auc_test)/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = open(r'./database_high_quality_st.pkl', 'rb')\n",
    "database_full = pickle.load(fl)\n",
    "##54 AC 55 ST\n",
    "data_input_full = database_full.iloc[:, 0:55]\n",
    "\n",
    "# Convert the target variable to binary based on the threshold\n",
    "threshold = 1\n",
    "data_output_full = (database_full.iloc[:, 55] < threshold).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_input_full, data_output_full, test_size=0.1, random_state=seed, stratify=data_output_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3cd93a",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_SVC = SVC(probability=True)\n",
    "param_svr = {\n",
    "     'kernel':['linear', 'poly', 'rbf'],\n",
    "              'max_iter':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500],\n",
    "          'degree':[2,3,4],\n",
    "         'gamma':['scale','auto'],\n",
    "              'coef0':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500]\n",
    "# 'coef0': [100], 'degree': [2], 'gamma': ['auto'], 'kernel': ['rbf'], 'max_iter': [200]\n",
    "       }\n",
    "SVR_full,SVR_full_score=gridsearch(model_SVC,param_svr,'Support Vector Regressor',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'Support Vector Regressor', SVR_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09839735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_KNeighborsClassifier = KNeighborsClassifier()\n",
    "param_knr = {\n",
    "    'n_neighbors':range(1,10),'weights':['uniform','distance'],\n",
    "             'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "         'leaf_size':[2,10,20,30,40,50,100],\n",
    "         'p':range(1,10)\n",
    "#     'algorithm': ['auto'], 'leaf_size': [2], 'n_neighbors': [7], 'p': [5], 'weights': ['distance']\n",
    "    }\n",
    "KNR_full,KNR_full_score=gridsearch(model_KNeighborsClassifier,param_knr,'K Nearest Neighbor Regressor',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'K Nearest Neighbor Regressor', KNR_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d883a0f",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_LGBMClassifier=LGBMClassifier(random_state=1, verbose=-1)\n",
    "param_lgbm = {\n",
    "    'boosting_type':['gbdt','rf'],\n",
    "    'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "    'subsample':[0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "    'n_estimators':[50,100,200,400],\n",
    "    'max_depth':[5,7,9,11,13,-1],\n",
    "    'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    "    'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "# 'boosting_type': ['gbdt'], 'learning_rate': [0.14], 'max_depth': [5], 'n_estimators': [100], 'reg_alpha': [1e-05], 'reg_lambda': [0.001], 'subsample': [0.4]\n",
    "}\n",
    "LGBM_full,LGBM_full_score=gridsearch(model_LGBMClassifier,param_lgbm,'LightGBM',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'LightGBM', LGBM_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b992e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_XGBClassifier=XGBClassifier(random_state=1,verbose=-1)\n",
    "param_xg={\n",
    "    'booster':['gbtree'],\n",
    "    'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "    'n_estimators':[100,200,400],\n",
    "    'max_depth':[3,5,7,9,11,13,-1],\n",
    "    'subsample':[0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "    'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    "    'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "# 'booster': ['gbtree'], 'learning_rate': [0.18], 'max_depth': [9], 'n_estimators': [100], 'reg_alpha': [0.0001], 'reg_lambda': [0.001], 'subsample': [0.75]\n",
    "}\n",
    "XG_full,XG_full_score=gridsearch(model_XGBClassifier,param_xg,'XGBoost',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'XGBoost', XG_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c462ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_CatBoostClassifier=CatBoostClassifier(random_state=1, verbose=0)\n",
    "param_cat = {\n",
    "    'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2],\n",
    "    'n_estimators':[100,200,400],\n",
    "    \"boosting_type\":[\"Plain\"],\n",
    "    'max_depth':[5,7,9,11],\n",
    "    'subsample':[0.4,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "    'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "# 'boosting_type': ['Plain'], 'learning_rate': [0.006], 'max_depth': [9], 'n_estimators': [100], 'reg_lambda': [1e-05], 'subsample': [0.65]\n",
    "}\n",
    "CAT_full,CAT_full_score=gridsearch(model_CatBoostClassifier,param_cat,'CatBoost',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'CatBoost', CAT_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ede86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_GradientBoostingClassifier = ensemble.GradientBoostingClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "    'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "    'n_estimators':[50,100,200,400],\n",
    "    'max_depth':[3,5,7,9,11,13,16],\n",
    "    'criterion':['friedman_mse','mae','mse'],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'loss':['deviance', 'exponential']\n",
    "# 'criterion': ['friedman_mse'], 'learning_rate': [0.12], 'loss': ['exponential'], 'max_depth': [5], 'max_features': ['auto'], 'n_estimators': [50]}\n",
    "GB_full,GB_full_score=gridsearch(model_GradientBoostingClassifier,param_GB,'GradientBoost',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'GradientBoost', GB_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03a8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestClassifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "    'n_estimators':[50,100,200,400,None],\n",
    "    'max_depth':[3,5,7,9,11,None],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features':['auto','sqrt','log2']\n",
    "# 'criterion': ['gini'], 'max_depth': [11], 'max_features': ['auto'], 'n_estimators': [50]\n",
    "}\n",
    "RF_full,RF_full_score=gridsearch(model_RandomForestClassifier,param_RF,'Random Forest',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'Random Forest', RF_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd640465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_DecisionTreeClassifier = DecisionTreeClassifier(random_state=1)\n",
    "param_dt={\n",
    "    'max_depth':[5,6,7,8,9,10,11,None],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter' : [ \"best\",'random']\n",
    "\n",
    "# 'criterion': ['gini'], 'max_depth': [5], 'max_features': ['auto'], 'splitter': ['best']\n",
    "}\n",
    "DT_full,DT_full_score=gridsearch(model_DecisionTreeClassifier,param_dt,'Decision Tree',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'Decision Tree', DT_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b43cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_AdaBoostClassifier = AdaBoostClassifier(random_state=1)\n",
    "param_ada={\n",
    "    'n_estimators':[50,100,200,400,800],\n",
    "    'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1]\n",
    "\n",
    "# 'learning_rate': [0.2],  'n_estimators': [800]\n",
    "}\n",
    "ADA_full,ADA_full_score=gridsearch(model_AdaBoostClassifier,param_ada,'AdaBoost',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'AdaBoost', ADA_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ANN_model_1layer(X, learning_rate, regular_term=0.001, neuron_number=50, drop_out_rate=0):\n",
    "    regularizer = keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal', activation='relu', kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal', activation='relu', kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Changed activation to sigmoid for binary classification\n",
    "    adam = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])  # Changed loss to binary_crossentropy\n",
    "    return model\n",
    "\n",
    "def create_ANN_model_2layer(X, learning_rate, regular_term=0.001, neuron_number=50, drop_out_rate=0):\n",
    "    regularizer = keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal', activation='relu', kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal', activation='relu', kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal', activation='relu', kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Changed activation to sigmoid for binary classification\n",
    "    adam = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])  # Changed loss to binary_crossentropy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANNClassifier1= KerasClassifier(build_fn=create_ANN_model_1layer(X=data_input_full,learning_rate=0.01), verbose=0)\n",
    "model_ANNClassifier2= KerasClassifier(build_fn=create_ANN_model_2layer(X=data_input_full,learning_rate=0.01), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list=[]\n",
    "for i in range(10,210,10):\n",
    "    epochs_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaf5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数候选值\n",
    "batch_size_list = [8,16,32]\n",
    "optimizers_list=['sgd', 'rmsprop', 'adam', 'adagrad']\n",
    "param_ann = dict(batch_size=batch_size_list, \n",
    "                 epochs=epochs_list,\n",
    "                optimizer=optimizers_list\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0fc06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ANN_1layer,ANN_1layer_score=gridsearch(model_ANNClassifier1,param_ann,'Artificial Neural Network 1 layer',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'Artificial Neural Network 1 layer', ANN_1layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65423e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ANN_2layer,ANN_2layer_score=gridsearch(model_ANNClassifier2,param_ann,'Artificial Neural Network 2 layer',X_train,y_train,X_test,y_test)\n",
    "predict_print_plot(data_input_full, X_train, X_test, y_train, y_test, 'Artificial Neural Network 2 layer', ANN_2layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adda85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_ann_1={'batch_size': [32], 'epochs': [190], 'optimizer': ['adam']}\n",
    "# param_ann_2={'batch_size': [16], 'epochs': [160], 'optimizer': ['rmsprop']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
