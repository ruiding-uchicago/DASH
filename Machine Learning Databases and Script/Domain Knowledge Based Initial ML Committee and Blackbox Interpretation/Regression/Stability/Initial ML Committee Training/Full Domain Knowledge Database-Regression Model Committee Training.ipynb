{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "seed=911\n",
    "###########import packages##########\n",
    "import catboost\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import *\n",
    "import pickle\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import  *\n",
    "###########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm \n",
    "# from keras.wrappers import scikit_learn\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "###########loading data##########\n",
    "loo = LeaveOneOut()\n",
    "# %matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00962e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########wrapping root mean square error for later calls##########\n",
    "def compute_mae_mse_rmse(target,prediction):\n",
    "    error = []\n",
    "    for i in range(len(target)):\n",
    "        error.append(target[i] - prediction[i])\n",
    "    squaredError = []\n",
    "    absError = []\n",
    "    for val in error:\n",
    "        squaredError.append(val * val)  # target-prediction之差平方\n",
    "        absError.append(abs(val))  # 误差绝对值\n",
    "    mae=sum(absError)/len(absError)  # 平均绝对误差MAE\n",
    "    mse=sum(squaredError)/len(squaredError)  # 均方误差MSE\n",
    "    RMSE=np.sqrt(sum(squaredError)/len(squaredError))\n",
    "    R2=r2_score(target,prediction)\n",
    "    return mae,mse,RMSE,R2\n",
    "def gridsearch(model,param,algorithm_name,X_train,y_train,X_test,y_test):\n",
    "    grid = GridSearchCV(model,param_grid=param,scoring='neg_mean_absolute_error',cv=10,n_jobs=8,verbose=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    ####Train####\n",
    "    print(\"=========Train===========\")\n",
    "    prediction_train = best_model.predict(X_train)\n",
    "    real_train=y_train.values\n",
    "    prediction_train_series=pd.Series(prediction_train)\n",
    "    real_train_series=pd.Series(real_train)\n",
    "    corr_ann_train = round(prediction_train_series.corr(real_train_series), 5)\n",
    "    error_val_train= compute_mae_mse_rmse(prediction_train,real_train)\n",
    "    print(error_val_train)\n",
    "    ####test####\n",
    "    print(\"=========Test===========\")\n",
    "    prediction_test = best_model.predict(X_test)\n",
    "    real_test=y_test.values\n",
    "    prediction_test_series=pd.Series(prediction_test)\n",
    "    real_test_series=pd.Series(real_test)\n",
    "    corr_ann_test = round(prediction_test_series.corr(real_test_series), 5)\n",
    "    error_val_test= compute_mae_mse_rmse(prediction_test,real_test)\n",
    "    print(error_val_test)\n",
    "    ####All####\n",
    "    print(\"=========All===========\")\n",
    "    prediction_all = best_model.predict(data_input_full)\n",
    "    real_all=data_output_full.values\n",
    "    prediction_all_series=pd.Series(prediction_all)\n",
    "    real_all_series=pd.Series(real_all)\n",
    "    corr_ann_all = round(prediction_all_series.corr(real_all_series), 5)\n",
    "    error_val_all= compute_mae_mse_rmse(prediction_all,real_all)\n",
    "    print(error_val_all)\n",
    "    \n",
    "    print(algorithm_name)\n",
    "    best_score=grid.best_score_\n",
    "    print('Best Regressor:',grid.best_params_,'Best Score:', best_score)\n",
    "    print('R2 TEST',error_val_test[3])\n",
    "    fig=plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    x_y_x=np.arange(-4,4,0.01)\n",
    "    x_y_y=np.arange(-4,4,0.01)\n",
    "    ax.scatter(prediction_train,real_train,c='blue',label='Train',alpha=0.25)\n",
    "    ax.scatter(prediction_test,real_test,c='red',label='Test',alpha=0.75)\n",
    "    ax.plot(x_y_x,x_y_y,c='black')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Predicted_Overpotential@10 mA cm-2')\n",
    "    plt.ylabel('Real_Overpotential@10 mA cm-2')\n",
    "    return best_model,error_val_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = open(r'./database_full_st.pkl','rb')\n",
    "database_full=pickle.load(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_full=database_full.iloc[:,0:55]\n",
    "data_output_full=database_full.iloc[:,55]\n",
    "X_train,X_test,y_train,y_test=train_test_split(data_input_full,data_output_full,test_size=0.1,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3cd93a",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_SVR = svm.SVR()\n",
    "param_svr = {\n",
    "'kernel':['linear', 'poly', 'rbf'],\n",
    "'max_iter':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500],\n",
    "'degree':[2,3,4],\n",
    "'gamma':['scale','auto'],\n",
    "'epsilon':[0.001,0.01,0.1,0.3,0.5,0.7,1],\n",
    "'coef0':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500]\n",
    "#     'coef0': [100], 'degree': [2], 'epsilon': [0.1], 'gamma': ['scale'], 'kernel': ['rbf'], 'max_iter': [400]\n",
    "       }\n",
    "SVR_full,SVR_full_score=gridsearch(model_SVR,param_svr,'Support Vector Regressor',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09839735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_KNeighborsRegressor = neighbors.KNeighborsRegressor()\n",
    "param_knr = {\n",
    "'n_neighbors':range(1,10),'weights':['uniform','distance'],\n",
    "'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "'leaf_size':[2,10,20,30,40,50,100],\n",
    "'p':range(1,10)\n",
    "#     'algorithm': ['ball_tree'], 'leaf_size': [20], 'n_neighbors':[ 5], 'p': [4], 'weights': ['distance']\n",
    "       }\n",
    "KNR_full,KNR_full_score=gridsearch(model_KNeighborsRegressor,param_knr,'K Nearest Neighbor Regressor',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d883a0f",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_LGBMRegressor=LGBMRegressor(random_state=1,verbose=0)\n",
    "param_lgbm = {\n",
    "'boosting_type':['gbdt','rf'],\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'subsample':[0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "'n_estimators':[50,100,200,400],\n",
    "'max_depth':[5,7,9,11,13,-1],\n",
    "'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    "'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "#     'boosting_type':[ 'gbdt'], 'learning_rate': [0.12], 'max_depth': [7], 'n_estimators': [400], 'reg_alpha': [0.001], 'reg_lambda': [1e-05], 'subsample': [0.4]\n",
    "}\n",
    "LGBM_full,LGBM_full_score=gridsearch(model_LGBMRegressor,param_lgbm,'LightGBM',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b992e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_XGRegressor=XGBRegressor(random_state=1)\n",
    "param_xg={\n",
    "'booster':['gbtree'],\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'n_estimators':[100,200,400],\n",
    "'max_depth':[3,5,7,9,11,13,-1],\n",
    "'subsample':[0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    "'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "# 'booster': ['gbtree'], 'learning_rate': [0.05], 'max_depth': [11], 'n_estimators': [100], 'reg_alpha': [1e-05], 'reg_lambda': [0], 'subsample': [0.45 ]   \n",
    "}\n",
    "XG_full,XG_full_score=gridsearch(model_XGRegressor,param_xg,'XGBoost',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c462ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_CatRegressor=catboost.CatBoostRegressor(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2],\n",
    "'n_estimators':[100,200,400],\n",
    "\"boosting_type\":[\"Plain\"],\n",
    "'max_depth':[5,7,9,11],\n",
    "'subsample':[0.4,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "#     'boosting_type': ['Plain'], 'learning_rate': [0.08], 'max_depth': [7], 'n_estimators': [400], 'reg_lambda': [0], 'subsample': [0.8]\n",
    "}\n",
    "CAT_full,CAT_full_score=gridsearch(model_CatRegressor,param_cat,'CatBoost',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ede86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'n_estimators':[50,100,200,400],\n",
    "'max_depth':[3,5,7,9,11,13,16],\n",
    "'criterion':['friedman_mse','mae','mse'],\n",
    "'max_features':['auto','sqrt','log2'],\n",
    "'loss':['ls', 'lad', 'huber', 'quantile']\n",
    "#     'criterion': ['friedman_mse'], 'learning_rate': [0.05], 'loss': ['lad'], 'max_depth': [9], 'max_features': ['auto'], 'n_estimators': [100]\n",
    "}\n",
    "GB_full,GB_full_score=gridsearch(model_GradientBoostingRegressor,param_GB,'GradientBoost',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03a8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "'n_estimators':[50,100,200,400,None],\n",
    "'max_depth':[3,5,7,9,11,None],\n",
    "'criterion':['mse','mae'],\n",
    "'max_features':['auto','sqrt','log2']\n",
    "# 'criterion': ['mae'], 'max_depth': [11], 'max_features': ['auto'], 'n_estimators': [400]\n",
    "}\n",
    "RF_full,RF_full_score=gridsearch(model_RandomForestRegressor,param_RF,'Random Forest',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd640465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_DecisionTreeRegressor = tree.DecisionTreeRegressor(random_state=1)\n",
    "param_dt={\n",
    "'max_depth':[5,6,7,8,9,10,11,None],\n",
    "'max_features':['auto','sqrt','log2'],\n",
    "'criterion' : [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "'splitter' : [ \"best\",'random']\n",
    "# 'criterion': ['mae'], 'max_depth': [6], 'max_features': ['auto'], 'splitter': ['best']\n",
    "}\n",
    "DT_full,DT_full_score=gridsearch(model_DecisionTreeRegressor,param_dt,'Decision Tree',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b43cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor(random_state=1)\n",
    "param_ada={\n",
    "'n_estimators':[50,100,200,400,800],\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'loss':['linear', 'square', 'exponential']  \n",
    "# 'learning_rate': [0.02], 'loss': ['exponential'], 'n_estimators': [100]\n",
    "}\n",
    "ADA_full,ADA_full_score=gridsearch(model_AdaBoostRegressor,param_ada,'AdaBoost',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ANN_model_1layer(X,learning_rate,regular_term=0.001,neuron_number=50,drop_out_rate=0):\n",
    "    regularizer=keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(1, input_dim=neuron_number, activation='linear'))\n",
    "    adam=optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='mae')\n",
    "    return model\n",
    "def create_ANN_model_2layer(X,learning_rate,regular_term=0.001,neuron_number=50,drop_out_rate=0):\n",
    "    regularizer=keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(1, input_dim=neuron_number, activation='linear'))\n",
    "    adam=optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANNRegressor1= KerasRegressor(build_fn=create_ANN_model_1layer(X=data_input_full,learning_rate=0.01), verbose=0)\n",
    "model_ANNRegressor2= KerasRegressor(build_fn=create_ANN_model_2layer(X=data_input_full,learning_rate=0.01), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list=[]\n",
    "for i in range(10,210,10):\n",
    "    epochs_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaf5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数候选值\n",
    "batch_size_list = [8,16,32]\n",
    "optimizers_list=['sgd', 'rmsprop', 'adam', 'adagrad']\n",
    "param_ann = dict(batch_size=batch_size_list, \n",
    "                 epochs=epochs_list,\n",
    "                optimizer=optimizers_list\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f30780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_ann_1={'batch_size': [16], 'epochs': [200], 'optimizer': ['adagrad']}\n",
    "# param_ann_2={'batch_size': [16], 'epochs': [150], 'optimizer': ['sgd']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0fc06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ANN_1layer,ANN_1layer_score=gridsearch(model_ANNRegressor1,param_ann,'Artificial Neural Network',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65423e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ANN_2layer,ANN_2layer_score=gridsearch(model_ANNRegressor2,param_ann,'Artificial Neural Network',X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eeb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def committee_predictor(models_with_scores, X_train, y_train, X_test, y_test, data_input_full, data_output_full):\n",
    "    # Create the committee predictor\n",
    "    def predict(X):\n",
    "        weighted_predictions = np.zeros(X.shape[0])\n",
    "        total_weight = 0\n",
    "        for model, weight in models_with_scores:\n",
    "            if weight < 0:\n",
    "                weight = 0\n",
    "            predictions = model.predict(X)\n",
    "            weighted_predictions += predictions * weight\n",
    "            total_weight += weight\n",
    "        if total_weight == 0:\n",
    "            return weighted_predictions\n",
    "        return weighted_predictions / total_weight\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    def compute_errors(predictions, real):\n",
    "        error = predictions - real\n",
    "        squared_error = np.square(error)\n",
    "        abs_error = np.abs(error)\n",
    "        mae = np.mean(abs_error)\n",
    "        mse = np.mean(squared_error)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(real, predictions)\n",
    "        return mae, mse, rmse, r2\n",
    "    \n",
    "    # Predict and compute errors for train, test, and all data\n",
    "    def compute_all_errors():\n",
    "        # Train\n",
    "        predictions_train = predict(X_train)\n",
    "        real_train = y_train.values\n",
    "        error_val_train = compute_errors(predictions_train, real_train)\n",
    "        \n",
    "        # Test\n",
    "        predictions_test = predict(X_test)\n",
    "        real_test = y_test.values\n",
    "        error_val_test = compute_errors(predictions_test, real_test)\n",
    "        \n",
    "        # All\n",
    "        predictions_all = predict(data_input_full)\n",
    "        real_all = data_output_full.values\n",
    "        error_val_all = compute_errors(predictions_all, real_all)\n",
    "        \n",
    "        return error_val_train, error_val_test, error_val_all\n",
    "    \n",
    "    error_val_train, error_val_test, error_val_all = compute_all_errors()\n",
    "    \n",
    "    # Output results\n",
    "    print(\"=========Train===========\")\n",
    "    print(error_val_train)\n",
    "    print(\"=========Test===========\")\n",
    "    print(error_val_test)\n",
    "    print(\"=========All===========\")\n",
    "    print(error_val_all)\n",
    "    \n",
    "    return error_val_train, error_val_test, error_val_all\n",
    "\n",
    "# Example usage\n",
    "models_with_scores = [   \n",
    "    (ANN_2layer, ANN_2layer_score),\n",
    "    (ANN_1layer, ANN_1layer_score),\n",
    "    (ADA_full, ADA_full_score),\n",
    "    (DT_full, DT_full_score),\n",
    "    (RF_full, RF_full_score),\n",
    "    (GB_full, GB_full_score),\n",
    "    (CAT_full, CAT_full_score),\n",
    "    (XG_full, XG_full_score),\n",
    "    (LGBM_full, LGBM_full_score),\n",
    "    (KNR_full, KNR_full_score),\n",
    "    (SVR_full, SVR_full_score)\n",
    "]\n",
    "error_val_train, error_val_test, error_val_all = committee_predictor(models_with_scores, X_train, y_train, X_test, y_test, data_input_full, data_output_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
