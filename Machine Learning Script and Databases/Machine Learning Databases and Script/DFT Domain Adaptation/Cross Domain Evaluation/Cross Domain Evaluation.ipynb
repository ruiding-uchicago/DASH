{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from numpy                 import array\n",
    "from sklearn               import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models          import Sequential\n",
    "from keras.layers          import *\n",
    "from sklearn               import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten,Conv2D, MaxPool2D,LSTM,Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers          import *\n",
    "from keras.models import save_model,load_model\n",
    "from numpy import save,load\n",
    "from sklearn.model_selection import KFold\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 INFO 和 WARNING 信息\n",
    "tf.get_logger().setLevel('ERROR')  # 只显示 ERROR 信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04928465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b75d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MSE  ：均方误差    ----->  预测值减真实值求平方后求均值\n",
    "RMSE ：均方根误差  ----->  对均方误差开方\n",
    "MAE  ：平均绝对误差----->  预测值减真实值求绝对值后求均值\n",
    "R2   ：决定系数，可以简单理解为反映模型拟合优度的重要的统计量\n",
    "\"\"\"\n",
    "def compute_metrics(pred,real):\n",
    "    MSE   = metrics.mean_squared_error(pred, real)\n",
    "    RMSE  = metrics.mean_squared_error(pred, real)**0.5\n",
    "    MAE   = metrics.mean_absolute_error(pred, real)\n",
    "    R2    = metrics.r2_score(pred, real)\n",
    "    print('均方误差: %.5f' % MSE)\n",
    "    print('均方根误差: %.5f' % RMSE)\n",
    "    print('平均绝对误差: %.5f' % MAE)\n",
    "    print('R2: %.5f' % R2)\n",
    "    return [MSE,RMSE,MAE,R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a091acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dscribe 1.2.1 numpy 1.23.5\n",
    "def load_trained_model(model_type, saved_model_path):\n",
    "    # Load the model\n",
    "    if model_type in [7, 8]:  # For TCN models\n",
    "        #laptop running have to change to complie=False and tf....\n",
    "        current_model = tf.keras.models.load_model(saved_model_path, custom_objects={'TCN': TCN},compile=False)\n",
    "    else:\n",
    "        current_model = tf.keras.models.load_model(saved_model_path,compile=False)\n",
    "    return current_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ff5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(model_type, model, data, batch_size=16):\n",
    "    \"\"\" 对数据进行分批预测，优化内存使用。 \"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    sample_prediction = model.predict(data[:1], verbose=0)\n",
    "\n",
    "    # 检查模型的返回类型，并据此获取形状\n",
    "    if isinstance(sample_prediction, list):\n",
    "        # 如果模型返回的是一个列表（多输出模型），取第一个输出的形状\n",
    "        pred_shape = sample_prediction[0].shape\n",
    "    else:\n",
    "        # 否则直接取返回值的形状\n",
    "        pred_shape = sample_prediction.shape\n",
    "\n",
    "    # 根据model_type进行特殊处理\n",
    "    if model_type in [8, 9]:\n",
    "        predictions = np.zeros((n_samples, pred_shape[1]), dtype='float16')  # 针对8和9的特殊预分配结果数组\n",
    "    else:\n",
    "        predictions = np.zeros((n_samples, *pred_shape[1:]), dtype='float16')  # 通常情况下的预分配结果数组\n",
    "\n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        batch_data = data[start:end]\n",
    "        batch_pred = model.predict(batch_data, verbose=0)\n",
    "\n",
    "        # 根据model_type进行特殊处理\n",
    "        if model_type in [8, 9]:\n",
    "            batch_pred = batch_pred.reshape(batch_pred.shape[0], batch_pred.shape[1])\n",
    "\n",
    "        predictions[start:end] = batch_pred\n",
    "\n",
    "        del batch_data  # 删除不再需要的批次数据\n",
    "        gc.collect()  # 调用垃圾回收\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MAE_within_percent(pred_test,real_test,pred_train,real_train,threshold):\n",
    "    difference_test=abs(pred_test-real_test)\n",
    "    difference_train=abs(pred_train-real_train)\n",
    "    i_test=0\n",
    "    i_train=0\n",
    "    for each in difference_test:\n",
    "        if each<threshold:\n",
    "            i_test+=1\n",
    "    for each in difference_train:\n",
    "        if each<threshold:\n",
    "            i_train+=1\n",
    "    percent_train=i_train/len(difference_train)\n",
    "    percent_test=i_test/len(difference_test)\n",
    "    return percent_train,percent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "import gc\n",
    "def evaluate_model_in_cv(predict_target, current_model, model_type, X_cv, y_cv, Outputscaler, start_fold=0, end_fold=10):\n",
    "    print('now model type is', model_type)\n",
    "    cvscores_TEST = []\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    \n",
    "    for fold_number, (_, test) in enumerate(kfold.split(X_cv, y_cv)):\n",
    "        print(f\"Fold {fold_number + 1} of {kfold.get_n_splits()}\")\n",
    "        if fold_number < start_fold or fold_number >= end_fold:\n",
    "            continue\n",
    "\n",
    "        ##### 给出预测 #####\n",
    "        try:\n",
    "            pred_test = batch_predict(model_type, current_model, X_cv[test])\n",
    "            pred_test = pred_test.reshape(-1, 1)\n",
    "            pred_test = Outputscaler.inverse_transform(pred_test)\n",
    "            real_test = Outputscaler.inverse_transform(y_cv[test].reshape(-1, 1))\n",
    "\n",
    "            TEST_SCORES = compute_metrics(pred_test, real_test)\n",
    "\n",
    "            ### 测试分数 ###\n",
    "            cvscores_TEST.append(TEST_SCORES)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        print(TEST_SCORES)\n",
    "\n",
    "    # 计算平均值和标准差\n",
    "    average_scores_TEST, std_scores_TEST = calculate_statistics(cvscores_TEST)\n",
    "    print(average_scores_TEST, std_scores_TEST)\n",
    "    return average_scores_TEST, std_scores_TEST\n",
    "\n",
    "# 计算平均值和标准差的辅助函数\n",
    "def calculate_statistics(scores):\n",
    "    averages = [sum(score) / len(score) for score in zip(*scores)]\n",
    "    std_devs = [(sum((x - avg) ** 2 for x in score) / len(score)) ** 0.5 for avg, score in zip(averages, zip(*scores))]\n",
    "    return averages, std_devs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae03f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def evaluate_all_combinations():\n",
    "    targets = [\"SLAB\", \"O\", \"OH\", \"OOH\"]\n",
    "    model_sources = [\"A_B\", \"A\", \"B\"]\n",
    "    model_types = list(range(1, 11))\n",
    "    dataset_map = {\"A\": \"B\", \"B\": \"A\", \"A_B\": \"A\"}  # 模型来源对应的数据集,A to B, Bto A and A_B to B\n",
    "\n",
    "    # 创建一个空的DataFrame来存储结果\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        for source in model_sources:\n",
    "            for model_type in model_types:\n",
    "                # A_B模型缺少2和4\n",
    "                if source == \"A_B\" and model_type in [2, 4]:\n",
    "                    continue\n",
    "                # 根据模型来源确定数据集\n",
    "                dataset = dataset_map[source]\n",
    "                print(\"current target:\",target,\"current source:\",source,\"current model_type:\" ,model_type,\"current dataset:\",dataset)\n",
    "                # 构建文件路径\n",
    "                model_path = f\"./{source} models/{source}_{target}_{model_type}_best_model.h5\"\n",
    "                input_path = f\"./{target}_INPUT_{dataset}_SCALED.npy\"\n",
    "                output_path = f\"./{target}_OUTPUT_{dataset}_SCALED.npy\"\n",
    "                scaler_path = f\"./{target}_OUTPUT_SCALER_{dataset}.pkl\"\n",
    "\n",
    "                # 加载模型和数据\n",
    "                model = load_trained_model(model_type, model_path)\n",
    "                X_scaled = np.load(input_path)\n",
    "                y_scaled = np.load(output_path)\n",
    "                if model_type==10:\n",
    "                    X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], X_scaled.shape[2], 1)\n",
    "\n",
    "                output_scaler = joblib.load(scaler_path)\n",
    "\n",
    "                # 评估模型\n",
    "                average_scores_TEST, std_scores_TEST = evaluate_model_in_cv(target, model, model_type, X_scaled, y_scaled, output_scaler)\n",
    "\n",
    "                # 准备要添加到DataFrame的数据\n",
    "                result_data = {\n",
    "                    \"Target\": target,\n",
    "                    \"Model Source\": source,\n",
    "                    \"Model Type\": model_type,\n",
    "                    \"Dataset\": dataset\n",
    "                }\n",
    "                for i, (avg_score, std_score) in enumerate(zip(average_scores_TEST, std_scores_TEST)):\n",
    "                    result_data[f\"Average Score {i+1}\"] = avg_score\n",
    "                    result_data[f\"Standard Deviation {i+1}\"] = std_score\n",
    "\n",
    "                # 将结果添加到DataFrame\n",
    "                results_df = results_df.append(result_data, ignore_index=True)\n",
    "\n",
    "    # 保存结果到CSV文件\n",
    "    results_df.to_csv(\"evaluation_results.csv\", index=False)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# 调用函数\n",
    "results_df = evaluate_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68273248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPUcompute )",
   "language": "python",
   "name": "gpucompute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
