{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778e9f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 3519,
     "status": "ok",
     "timestamp": 1702074441281,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "7778e9f3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from numpy                 import array\n",
    "from sklearn               import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models          import Sequential\n",
    "from keras.layers          import *\n",
    "from sklearn               import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten,Conv2D, MaxPool2D,LSTM,Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers          import *\n",
    "from keras.models import save_model,load_model\n",
    "from numpy import save,load\n",
    "from sklearn.model_selection import KFold\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 INFO 和 WARNING 信息\n",
    "tf.get_logger().setLevel('ERROR')  # 只显示 ERROR 信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FzfIinytIYac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702074442331,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "FzfIinytIYac",
    "outputId": "50e5647d-9551-485c-be56-4b57ebd97454"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960e7e6",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702074442331,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "6960e7e6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MSE  ：均方误差    ----->  预测值减真实值求平方后求均值\n",
    "RMSE ：均方根误差  ----->  对均方误差开方\n",
    "MAE  ：平均绝对误差----->  预测值减真实值求绝对值后求均值\n",
    "R2   ：决定系数，可以简单理解为反映模型拟合优度的重要的统计量\n",
    "\"\"\"\n",
    "def compute_metrics(pred,real):\n",
    "    MSE   = metrics.mean_squared_error(pred, real)\n",
    "    RMSE  = metrics.mean_squared_error(pred, real)**0.5\n",
    "    MAE   = metrics.mean_absolute_error(pred, real)\n",
    "    R2    = metrics.r2_score(pred, real)\n",
    "    print('均方误差: %.5f' % MSE)\n",
    "    print('均方根误差: %.5f' % RMSE)\n",
    "    print('平均绝对误差: %.5f' % MAE)\n",
    "    print('R2: %.5f' % R2)\n",
    "    return [MSE,RMSE,MAE,R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ba683",
   "metadata": {
    "executionInfo": {
     "elapsed": 8592,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "c68ba683"
   },
   "outputs": [],
   "source": [
    "#load B data\n",
    "data_input = np.load('./data_input_sm_ew_acsf_rcut6_B.npy').astype(np.float16)\n",
    "data_output = np.load('./data_output_sm_ew_acsf_rcut6_OH_B.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4ec85",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "b9d4ec85"
   },
   "outputs": [],
   "source": [
    "# 建构模型\n",
    "def set_up_model(model_type,X_train,X_test,y_train,y_test):\n",
    "    if model_type == 1:\n",
    "        # 双向 LSTM\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(100),\n",
    "                                input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    if model_type == 2:\n",
    "        # simple RNN\n",
    "        model = Sequential()\n",
    "        model.add(SimpleRNN(units=100, return_sequences=True,activation='relu',\n",
    "                       input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(SimpleRNN(units=100))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    if model_type == 3:\n",
    "    #     GRU\n",
    "        model = Sequential()\n",
    "        model.add(GRU(units=100, return_sequences=True,activation='relu',\n",
    "                       input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(GRU(units=100))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "    if model_type == 4:\n",
    "        #simple one layer CNN\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, activation='relu',\n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(units=y_train.shape[1]))\n",
    "    if model_type == 5:\n",
    "        #multilayer CNN\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(units=y_train.shape[1]))\n",
    "    if model_type == 6:\n",
    "        #CNN-LSTM\n",
    "#         y_train_sp = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "#         y_test_sp = y_test.reshape((y_test.shape[0], y_test.shape[1], 1))\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu',\n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(RepeatVector(y_train.shape[1]))\n",
    "        model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "        model.add(TimeDistributed(Dense(y_train.shape[1])))\n",
    "\n",
    "    if model_type == 7:\n",
    "        #单层TCN\n",
    "        model = Sequential([\n",
    "        TCN(input_shape=(X_train.shape[1],X_train.shape[2]),\n",
    "            nb_filters=64,\n",
    "            kernel_size=2,\n",
    "            nb_stacks=1,\n",
    "            dilations=(1, 2, 4, 8, 16,32,64,128,256,512),\n",
    "            padding='causal',\n",
    "            use_skip_connections=True,\n",
    "            dropout_rate=0.0,\n",
    "            return_sequences=False,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            use_batch_norm=False,\n",
    "            use_layer_norm=False,\n",
    "            use_weight_norm=False,\n",
    "            ),\n",
    "        Dense(y_train.shape[1], activation='linear')\n",
    "    ])\n",
    "    if model_type == 8:\n",
    "        #多层TCN\n",
    "        model = Sequential([\n",
    "        TCN(input_shape=(X_train.shape[1],X_train.shape[2]),\n",
    "            nb_filters=64,\n",
    "            kernel_size=2,\n",
    "            nb_stacks=1,\n",
    "            dilations=(1, 2, 4, 8, 16,32,64,128,256,512),\n",
    "            padding='causal',\n",
    "            use_skip_connections=True,\n",
    "            dropout_rate=0.0,\n",
    "            return_sequences=True,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            use_batch_norm=False,\n",
    "            use_layer_norm=False,\n",
    "            use_weight_norm=False,\n",
    "            ),\n",
    "        TCN(\n",
    "            return_sequences=False\n",
    "            ),\n",
    "        Dense(y_train.shape[1], activation='linear')\n",
    "    ])\n",
    "    if model_type == 9:\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=128, kernel_size=2, activation='relu',\n",
    "                         input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(units=y_train.shape[1]))\n",
    "    if model_type == 10:\n",
    "        model = Sequential()\n",
    "        # 表示我们的网络将学习16个滤波器 每个滤波器的大小都是5×5，步长为1\n",
    "        model.add(Conv2D(32, kernel_size=2, strides=1, padding='valid', input_shape=(X_train.shape[1],X_train.shape[2],1),activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        model.add(Conv2D(16, kernel_size=2, strides=1, padding='valid',activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        # 展开\n",
    "        model.add(Flatten())\n",
    "        # 接下来相当于有两层full-connected网络\n",
    "        # 120个神经元 全连接网络\n",
    "        model.add(Dense(100,activation=\"relu\"))\n",
    "        # model.add(Dense(50,activation=\"relu\"))\n",
    "        # 84个神经元 全连接网络\n",
    "        model.add(Dense(y_train.shape[1],activation=\"linear\"))\n",
    "    if model_type==11:\n",
    "        model = Sequential()\n",
    "        # 表示我们的网络将学习6个滤波器 每个滤波器的大小都是3×3，步长为1\n",
    "        model.add(Conv2D(128, kernel_size=2, strides=1, padding='valid', input_shape=(X_train.shape[1],X_train.shape[2],1),activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        # 表示我们的网络将学习16个滤波器 每个滤波器的大小都是5×5，步长为1\n",
    "        model.add(Conv2D(64, kernel_size=2, strides=1, padding='valid',activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        model.add(Conv2D(32, kernel_size=2, strides=1, padding='valid',activation=\"relu\"))\n",
    "        # 2×2的最大池化层 步长为2\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        # 展开\n",
    "        model.add(Flatten())\n",
    "        # 接下来相当于有两层full-connected网络\n",
    "        # 120个神经元 全连接网络\n",
    "        model.add(Dense(100,activation=\"relu\"))\n",
    "        # model.add(Dense(50,activation=\"relu\"))\n",
    "        # 84个神经元 全连接网络\n",
    "        model.add(Dense(y_train.shape[1],activation=\"linear\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ead91e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "d8ead91e"
   },
   "outputs": [],
   "source": [
    "def train_model(model_type,model,number_batchsize,n_epochs,X_train,X_test,y_train,y_test):\n",
    "    print('type of model is',model_type)\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=number_batchsize,\n",
    "                        epochs=n_epochs,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        validation_freq=1)                  #测试的epoch间隔数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c91a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "8f4c91a6"
   },
   "outputs": [],
   "source": [
    "def prediction(model_type,model,Input):\n",
    "    pred=model.predict(Input)\n",
    "    if model_type in [8,9]:\n",
    "        pred=pred.reshape(pred.shape[0],pred.shape[1])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eed6ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "76eed6ad"
   },
   "outputs": [],
   "source": [
    "def compute_MAE_within_percent(pred_test,real_test,pred_train,real_train,threshold):\n",
    "    difference_test=abs(pred_test-real_test)\n",
    "    difference_train=abs(pred_train-real_train)\n",
    "    i_test=0\n",
    "    i_train=0\n",
    "    for each in difference_test:\n",
    "        if each<threshold:\n",
    "            i_test+=1\n",
    "    for each in difference_train:\n",
    "        if each<threshold:\n",
    "            i_train+=1\n",
    "    percent_train=i_train/len(difference_train)\n",
    "    percent_test=i_test/len(difference_test)\n",
    "    return percent_train,percent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835bbe3",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "7835bbe3"
   },
   "outputs": [],
   "source": [
    "def get_mean_and_std_and_best_model_serie_number(cvscores_result):\n",
    "    MSE_LIST=[]\n",
    "    RMSE_LIST=[]\n",
    "    MAE_LIST=[]\n",
    "    R2_LIST=[]\n",
    "    PERCENT_LIST=[]\n",
    "    for each_list in cvscores_result:\n",
    "        MSE_LIST.append(each_list[0])\n",
    "        RMSE_LIST.append(each_list[1])\n",
    "        MAE_LIST.append(each_list[2])\n",
    "        R2_LIST.append(each_list[3])\n",
    "        PERCENT_LIST.append(each_list[4])\n",
    "    print('metrics  mean  std')\n",
    "    print('MSE',np.mean(MSE_LIST), np.std(MSE_LIST))\n",
    "    print('RMSE',np.mean(RMSE_LIST), np.std(RMSE_LIST))\n",
    "    print('MAE',np.mean(MAE_LIST), np.std(MAE_LIST))\n",
    "    print('R2',np.mean(R2_LIST), np.std(R2_LIST))\n",
    "    print('PERCENT',np.mean(PERCENT_LIST), np.std(PERCENT_LIST))\n",
    "    return R2_LIST.index(max(R2_LIST)),np.mean(R2_LIST),np.mean(PERCENT_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ah3ard_rcyZk",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702074451410,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "Ah3ard_rcyZk"
   },
   "outputs": [],
   "source": [
    "def batch_predict(model_type, model, data, batch_size=16):\n",
    "    \"\"\" 对数据进行分批预测，优化内存使用。 \"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    sample_prediction = model.predict(data[:1], verbose=0)\n",
    "\n",
    "    # 检查模型的返回类型，并据此获取形状\n",
    "    if isinstance(sample_prediction, list):\n",
    "        # 如果模型返回的是一个列表（多输出模型），取第一个输出的形状\n",
    "        pred_shape = sample_prediction[0].shape\n",
    "    else:\n",
    "        # 否则直接取返回值的形状\n",
    "        pred_shape = sample_prediction.shape\n",
    "\n",
    "    # 根据model_type进行特殊处理\n",
    "    if model_type in [8, 9]:\n",
    "        predictions = np.zeros((n_samples, pred_shape[1]), dtype='float16')  # 针对8和9的特殊预分配结果数组\n",
    "    else:\n",
    "        predictions = np.zeros((n_samples, *pred_shape[1:]), dtype='float16')  # 通常情况下的预分配结果数组\n",
    "\n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        batch_data = data[start:end]\n",
    "        batch_pred = model.predict(batch_data, verbose=0)\n",
    "\n",
    "        # 根据model_type进行特殊处理\n",
    "        if model_type in [8, 9]:\n",
    "            batch_pred = batch_pred.reshape(batch_pred.shape[0], batch_pred.shape[1])\n",
    "\n",
    "        predictions[start:end] = batch_pred\n",
    "\n",
    "        del batch_data  # 删除不再需要的批次数据\n",
    "        gc.collect()  # 调用垃圾回收\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WDujHT8h6fED",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702074451542,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "WDujHT8h6fED"
   },
   "outputs": [],
   "source": [
    "def fine_tune_evaluate_in_cv_and_save(predict_target, saved_model_path, model_type, X_cv, y_cv, X_train, X_test, y_train, y_test, lr, loss_type, batch_number, epoch_number, Outputscaler, start_fold=0, end_fold=10, freeze_layers=False):\n",
    "    best_R2 = -float('inf')\n",
    "    best_model_filename = \"\"\n",
    "\n",
    "    while True:\n",
    "        print(f\"Retry attempt: {retry_count + 1}\")\n",
    "        print('now model type is', model_type)\n",
    "        cvscores_TRAIN = []\n",
    "        cvscores_TEST = []\n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "        for fold_number, (train, test) in enumerate(kfold.split(X_cv, y_cv)):\n",
    "            print(f\"Fold {fold_number + 1} of {kfold.get_n_splits()}\")\n",
    "            if fold_number < start_fold or fold_number >= end_fold:\n",
    "                continue\n",
    "\n",
    "            current_model = load_and_compile_model(model_type, saved_model_path, lr, loss_type, freeze_layers)\n",
    "            train_model(model_type, current_model, batch_number, epoch_number, X_cv[train], X_cv[test], y_cv[train], y_cv[test])\n",
    "\n",
    "            TRAIN_SCORES = []\n",
    "            TEST_SCORES = []\n",
    "            try:\n",
    "                pred_test, pred_train, real_test, real_train = get_predictions(model_type, current_model, X_cv, y_cv, Outputscaler, train, test)\n",
    "                TRAIN_SCORES, TEST_SCORES = compute_all_scores(pred_test, pred_train, real_test, real_train)\n",
    "\n",
    "                cvscores_TRAIN.append(TRAIN_SCORES)\n",
    "                cvscores_TEST.append(TEST_SCORES)\n",
    "            except Exception as e:\n",
    "                print(\"error found, error is:\", e)\n",
    "\n",
    "            print(TRAIN_SCORES)\n",
    "            print(TEST_SCORES)\n",
    "\n",
    "            # Save the model if it has the best R2 score so far\n",
    "            current_R2 = TEST_SCORES[-2]  # Assuming the second last score is R2\n",
    "            if current_R2 > best_R2:\n",
    "                best_R2 = current_R2\n",
    "                if best_model_filename:\n",
    "                    os.remove(best_model_filename)  # Remove the previous best model\n",
    "                best_model_filename = f\"A_B_{predict_target}_{model_type}_fold{fold_number}.h5\"\n",
    "                current_model.save(best_model_filename)\n",
    "\n",
    "            del current_model\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "            with open(f\"{predict_target}_{model_type}_fold{fold_number}_performance.txt\", \"w\") as file:\n",
    "                for train_score, test_score in zip(TRAIN_SCORES, TEST_SCORES):\n",
    "                    file.write(f\"TRAIN SCORE: {train_score}\\n\")\n",
    "                    file.write(f\"TEST SCORE: {test_score}\\n\")\n",
    "                print('file saved')\n",
    "\n",
    "        retry_count += 1\n",
    "        if retry_count >= max_retries:\n",
    "            print(f\"Max retries reached. Ending process.\")\n",
    "            break\n",
    "\n",
    "    best_model_number, average_R2, average_percent = get_mean_and_std_and_best_model_serie_number(cvscores_TEST)\n",
    "    print(\"Best model saved as:\", best_model_filename)\n",
    "\n",
    "    return average_R2, average_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DZBhZpI4oxw5",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702074451543,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "DZBhZpI4oxw5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ada9c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 39307,
     "status": "ok",
     "timestamp": 1702074490848,
     "user": {
      "displayName": "Ding Rui",
      "userId": "07630738670462344821"
     },
     "user_tz": 360
    },
    "id": "b4ada9c4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "Minmaxsc  = MinMaxScaler(feature_range=(0, 1))\n",
    "Minmaxsc2  = MinMaxScaler(feature_range=(0, 1))\n",
    "Stdsc  = StandardScaler()\n",
    "Stdsc2  = StandardScaler()\n",
    "MAsc  = MaxAbsScaler()\n",
    "MAsc2  = MaxAbsScaler()\n",
    "Rsc  = RobustScaler()\n",
    "Rsc2  = RobustScaler()\n",
    "\n",
    "X = Minmaxsc.fit_transform(data_input.reshape(-1, data_input.shape[-1])).reshape(data_input.shape)\n",
    "y = Stdsc2.fit_transform(data_output.reshape(-1,1))\n",
    "random_seed=1\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=random_seed,test_size=0.1)\n",
    "\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "\n",
    "train_score_list=[]\n",
    "test_score_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存归一化器\n",
    "joblib.dump(Minmaxsc, 'OH_INPUT_SCALER_B.pkl')\n",
    "joblib.dump(Stdsc2, 'OH_OUTPUT_SCALER_B.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31963457",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f82d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f02f82d4",
    "outputId": "ff041953-d455-40b3-cdb0-95c54d8c85eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range (1,11):\n",
    "    freeze_layers=False\n",
    "    serial_R2,serial_percent=fine_tune_evaluate_in_cv_and_save('O',f'./O_{i}_best_model.h5',i,X,y,X_train,X_test,y_train,y_test,0.001,'mse',32,25,Rsc2,freeze_layers=freeze_layers)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "cell_execution_strategy": "setup",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (GPUcompute)",
   "language": "python",
   "name": "gpucompute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
