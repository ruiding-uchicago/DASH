{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from numpy                 import array\n",
    "from sklearn               import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models          import Sequential\n",
    "from keras.layers          import *\n",
    "from sklearn               import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten,Conv2D, MaxPool2D,LSTM,Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers          import *\n",
    "from keras.models import save_model,load_model\n",
    "from numpy import save,load\n",
    "from sklearn.model_selection import KFold\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 INFO 和 WARNING 信息\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dscribe.descriptors import SOAP\n",
    "from dscribe.descriptors import MBTR,ACSF,CoulombMatrix,EwaldSumMatrix,SineMatrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core.surface import Slab\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "import ase.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62852069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####decribe parameters#####\n",
    "rcut = 6\n",
    "#####decribe parameters#####\n",
    "sm = SineMatrix(\n",
    "    n_atoms_max=96,\n",
    "    permutation=\"sorted_l2\",\n",
    "    sparse=False,\n",
    "    flatten=False)\n",
    "ew=EwaldSumMatrix(\n",
    "    n_atoms_max=96,\n",
    "    permutation=\"none\",flatten=False,sparse=False)\n",
    "acsf=ACSF(species=['Na','Mg','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Rb','Sr','Y','Zr','Nb','Mo','Tc','Rh','Pd','Ag','Cd','Cs','Ba','Os','Re','Ir','Pt','Au','Ga', 'In', 'Sn', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Hg', 'Tl', 'Pb', 'Bi', 'Li', 'Al','Ru','O'],\n",
    "# acsf=ACSF(species=['Na','Mg','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Rb','Sr','Y','Zr','Nb','Mo','Tc','Rh','Pd','Ag','Cd','Cs','Ba','Os','Re','Ir','Pt','Au','Ru','O'],\n",
    "    rcut=rcut,\n",
    "    periodic=True,\n",
    "    g2_params=[[1, 1], [1, 2], [1, 3]],\n",
    "    g4_params=[[1, 1, 1], [1, 2, 1], [1, 1, -1], [1, 2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "my_key='BJU2qDd4gpCPO0rf'\n",
    "from pymatgen.core import Structure, Lattice\n",
    "from pymatgen.core import Molecule\n",
    "from pymatgen.analysis.adsorption import *\n",
    "from pymatgen.core.surface import generate_all_slabs\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from matplotlib import pyplot as plt\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.vasp.inputs import Poscar\n",
    "from pymatgen.io.vasp.inputs import Kpoints\n",
    "from pymatgen.io.vasp.inputs import Incar\n",
    "from pymatgen.io.vasp.inputs import Potcar\n",
    "from pymatgen.io.vasp.inputs import PotcarSingle\n",
    "from numpy import array\n",
    "from pymatgen.io.vasp.sets import MPRelaxSet\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import re\n",
    "import numpy as np\n",
    "def sum_all(object_list):\n",
    "    sum_result=0\n",
    "    for strings in object_list:\n",
    "        b=int(strings)\n",
    "        sum_result+=b\n",
    "    return sum_result\n",
    "import random\n",
    "m= MPRester(my_key)\n",
    "element_list=['K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Rb','Sr','Y','Zr','Nb','Mo','Tc','Rh','Cs','Ba','Os','Re','Ir']\n",
    "extra_element_list=['Ga', 'In', 'Sn', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Hg', 'Tl', 'Pb', 'Bi', 'Li', 'Al']\n",
    "\n",
    "\n",
    "RuO2=m.get_structure_by_material_id('mp-825')\n",
    "struct = SpacegroupAnalyzer(RuO2).get_conventional_standard_structure()\n",
    "struct=reorient_z(struct)\n",
    "slabs = generate_all_slabs(struct, 1,12.0, 15.0, center_slab=True)\n",
    "m_index=(1,1,0)\n",
    "slab_dict = {slab.miller_index:slab for slab in slabs}                   \n",
    "RuO2_110=slab_dict[m_index]\n",
    "RuO2_110.make_supercell([[2,0,0],\n",
    "                          [0,2,0],\n",
    "                          [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec180f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_crystal_to_des(ase_atoms):\n",
    "    des1=sm.create(ase_atoms,n_jobs=-1)\n",
    "    des2=ew.create(ase_atoms,n_jobs=-1)\n",
    "    des3=acsf.create(ase_atoms,n_jobs=-1)\n",
    "    new_des=np.concatenate((des1,des2),axis=1)\n",
    "    new_des=np.concatenate((new_des,des3),axis=1)\n",
    "    new_des=new_des.reshape(768,969)\n",
    "    return new_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dscribe 1.2.1 numpy 1.23.5\n",
    "def load_trained_domain_adapted_model(model_type, saved_model_path):\n",
    "    # Load the model\n",
    "    if model_type in [7, 8]:  # For TCN models\n",
    "        #laptop running have to change to complie=False and tf....\n",
    "        current_model = tf.keras.models.load_model(saved_model_path, custom_objects={'TCN': TCN},compile=False)\n",
    "    else:\n",
    "        current_model = tf.keras.models.load_model(saved_model_path,compile=False)\n",
    "    return current_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c283d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_model(new_des, loaded_model, INPUT_SCALER, OUTPUT_SCALER, model_type):\n",
    "    # 对新晶体数据进行归一化\n",
    "    new_des_normalized = INPUT_SCALER.transform(new_des.reshape(-1, new_des.shape[-1])).reshape(new_des.shape)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    predicted = loaded_model.predict(new_des_normalized.reshape(1, *new_des_normalized.shape),verbose=0)\n",
    "\n",
    "    # 特殊处理模型类型6\n",
    "    if model_type == 6:\n",
    "        # 确保预测结果的形状正确\n",
    "        predicted = predicted.reshape(-1, 1)\n",
    "    # 逆归一化预测结果\n",
    "    predicted_original = OUTPUT_SCALER.inverse_transform(predicted)\n",
    "    return predicted_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312620d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model_3=load_trained_domain_adapted_model(3,\"Domain_Adapted_SLAB_3.h5\")\n",
    "loaded_model_5=load_trained_domain_adapted_model(5,\"Domain_Adapted_SLAB_5.h5\")\n",
    "loaded_model_6=load_trained_domain_adapted_model(6,\"Domain_Adapted_SLAB_6.h5\")\n",
    "loaded_model_7=load_trained_domain_adapted_model(7,\"Domain_Adapted_SLAB_7.h5\")\n",
    "loaded_model_9=load_trained_domain_adapted_model(9,\"Domain_Adapted_SLAB_9.h5\")\n",
    "SLAB_INPUT_SCALER_B=joblib.load(\"SLAB_INPUT_SCALER_B.pkl\")\n",
    "SLAB_OUTPUT_SCALER_B=joblib.load(\"SLAB_OUTPUT_SCALER_B.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19364caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(new_des):\n",
    "    predictions = [\n",
    "        predict_single_model(new_des, loaded_model_3, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 3)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_5, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 5)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_6, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 6)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_7, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 7)[0][0],\n",
    "        predict_single_model(new_des, loaded_model_9, SLAB_INPUT_SCALER_B, SLAB_OUTPUT_SCALER_B, 9)[0][0]\n",
    "    ]\n",
    "    variance = np.var(predictions)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_energy(new_des):\n",
    "    #0.9950695604822077\n",
    "    predict_3=predict_single_model(new_des,loaded_model_3,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,3)[0][0]\n",
    "    #0.9965353226220658\n",
    "    predict_5=predict_single_model(new_des,loaded_model_5,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,5)[0][0]\n",
    "    #0.996410743935558\n",
    "    predict_6=predict_single_model(new_des,loaded_model_6,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,6)[0][0]\n",
    "    #0.9938711994655637\n",
    "    predict_7=predict_single_model(new_des,loaded_model_7,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,7)[0][0]\n",
    "    #0.9973437346125353\n",
    "    predict_9=predict_single_model(new_des,loaded_model_9,SLAB_INPUT_SCALER_B,SLAB_OUTPUT_SCALER_B,9)[0][0]\n",
    "    sum_weight=0.9950695604822077+0.9965353226220658+0.996410743935558+0.9938711994655637+0.9973437346125353\n",
    "    sum_result=0.9950695604822077*predict_3+0.9965353226220658*predict_5+0.996410743935558*predict_6+0.9938711994655637*predict_7+0.9973437346125353*predict_9\n",
    "    return sum_result/sum_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ase_atoms = AseAtomsAdaptor.get_atoms(RuO2_110)\n",
    "base_des_ruo2=convert_crystal_to_des(ase_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruo2_slab_predict=calculate_weighted_energy(base_des_ruo2)\n",
    "print(ruo2_slab_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3286ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pymatgen.core.surface import Slab\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "def calculate_energy(new_structure):\n",
    "    ase_atoms = AseAtomsAdaptor.get_atoms(new_structure)\n",
    "    new_des=convert_crystal_to_des(ase_atoms)\n",
    "    weighted_energy_final=calculate_weighted_energy(new_des)\n",
    "#     print(weighted_energy_final)\n",
    "    return weighted_energy_final\n",
    "\n",
    "# 修改适应度函数\n",
    "def evaluate(individual):\n",
    "    new_structure = RuO2_110.copy()\n",
    "    for site, element in individual:\n",
    "        new_structure.replace(site, element)\n",
    "    return calculate_energy(new_structure),\n",
    "element_list_A = ['K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Rh', 'Cs', 'Ba', 'Os', 'Re', 'Ir']\n",
    "element_list_B = ['Ga', 'In', 'Sn', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'Hg', 'Tl', 'Pb', 'Bi', 'Li', 'Al']\n",
    "\n",
    "# 合并元素列表\n",
    "combined_elements = element_list_A + element_list_B\n",
    "# 遗传算法参数\n",
    "NUM_SITES = 32  # 晶格中的Ru原子数量\n",
    "NUM_DOPANTS = 16  # 掺杂原子总数\n",
    "\n",
    "def create_individual():\n",
    "    num_elements = random.randint(1, 3)  # 随机选择1到3种元素\n",
    "    chosen_elements = random.sample(combined_elements, num_elements)\n",
    "    num_sites = random.randint(1, min(16, NUM_SITES))  # 最多22个位置，但不超过晶格位置总数\n",
    "    sites = random.sample(range(NUM_SITES), num_sites)\n",
    "    individual = []\n",
    "    for _ in range(num_sites):\n",
    "        site = random.choice(sites)\n",
    "        element = random.choice(chosen_elements)\n",
    "        individual.append((site, element))\n",
    "    return individual\n",
    "# 自定义交叉操作\n",
    "def cxCustom(ind1, ind2):\n",
    "    # Ensure ind1 is the shorter individual\n",
    "    if len(ind1) > len(ind2):\n",
    "        ind1, ind2 = ind2, ind1\n",
    "\n",
    "    # Randomly choose crossover point\n",
    "    cxpoint = random.randint(0, len(ind1))\n",
    "    ind1[cxpoint:], ind2[cxpoint:] = ind2[cxpoint:], ind1[cxpoint:]\n",
    "\n",
    "    # Fix duplicates\n",
    "    fix_duplicate(ind1)\n",
    "    fix_duplicate(ind2)\n",
    "    return ind1, ind2\n",
    "\n",
    "# 自定义变异操作\n",
    "def mutShuffleIndexes(individual, indpb):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            # Mutate either the site or the element\n",
    "            if random.random() < 0.5:\n",
    "                # Mutate the site\n",
    "                new_site = random.randrange(NUM_SITES)\n",
    "                individual[i] = (new_site, individual[i][1])\n",
    "            else:\n",
    "                # Mutate the element\n",
    "                new_element = random.choice(combined_elements)\n",
    "                individual[i] = (individual[i][0], new_element)\n",
    "    fix_duplicate(individual)\n",
    "    return individual,\n",
    "\n",
    "def fix_duplicate(individual):\n",
    "    seen_sites = set()\n",
    "    for i, (site, element) in enumerate(individual):\n",
    "        # 检查是否已经看到了这个 site\n",
    "        if site in seen_sites:\n",
    "            # 找到一个新的未使用的 site\n",
    "            new_site = next(s for s in range(NUM_SITES) if s not in seen_sites)\n",
    "            individual[i] = (new_site, element)\n",
    "        seen_sites.add(individual[i][0])\n",
    "\n",
    "\n",
    "# 创建适应度类和个体类\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # 最小化问题\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# 初始化工具箱\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"indices\", random.sample, range(NUM_SITES), NUM_DOPANTS)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "toolbox.register(\"mate\", cxCustom)\n",
    "toolbox.register(\"mutate\", mutShuffleIndexes, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 运行遗传算法\n",
    "def run_genetic_algorithm():\n",
    "    pop = toolbox.population(n=2000)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", lambda x: min(v[0] for v in x))  # 修改最小值统计\n",
    "    stats.register(\"avg\", lambda x: sum(v[0] for v in x) / len(x))  # 修改平均值统计\n",
    "\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, \n",
    "                                   stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    return hof[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed597d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_repeat_time in range(1,1001):\n",
    "    best_structure = run_genetic_algorithm()\n",
    "    print(\"best_doping_structure\", best_structure,\"monte_carlo times:\",run_repeat_time)\n",
    "    run_repeat_time+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
